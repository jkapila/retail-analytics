[
  {
    "objectID": "price_demand.html",
    "href": "price_demand.html",
    "title": "Understanding impact of price change on demand (Theory)",
    "section": "",
    "text": "Price elasticity of demand is the ratio of the percentage change in quantity demanded of a product to the percentage change in price.\n\n\n\\(Price Elasticity = (d(Quantity)/Quantity)) / (d(Price)/Price))\\)\n\n\n\n\nPerformed regression analysis to understand the relationship between price and demand within category."
  },
  {
    "objectID": "price_demand.html#regression-overview",
    "href": "price_demand.html#regression-overview",
    "title": "Understanding impact of price change on demand (Theory)",
    "section": "Regression Overview",
    "text": "Regression Overview\nRegression analysis is a set of statistical methods used for the estimation of relationships between a dependent variable and one or more independent variables. It can be utilized to assess the strength of the relationship between variables and for modeling the future relationship between them.\n\nEquation:\n\n\n\\(Y = a + b*x1 + c*x2 + d*x3 + ... + e\\)\n\nWhere: Y – Dependent (target) variable\nx1, x2, x3 – Independent (explanatory) variables a – Intercept b, c, d – Slopes e – Residual (error)\n\nInterpretation: one unit change in variable x1 will impact Y by the factor of b, keeping all the values as it is\n\n\nEquation for our case:\nRegression models will be build on category level to understand the interaction of prices changes within category\n\n\\(Category Demand = const+coef_1*Price_{subcat1}+coef_2*Price_{subcat2}+coef_3*Price_{subcat3}+...+e\\)"
  },
  {
    "objectID": "supermart analysis-regression - 9 nov.html",
    "href": "supermart analysis-regression - 9 nov.html",
    "title": "Price Demand Analysis on Retail Data",
    "section": "",
    "text": "Code\n# Import Libraries\nfrom nbdev.showdoc import *\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\nimport plotly.io as pio\npio.renderers.default='notebook'\nfrom IPython.display import display_html \nimport warnings\nwarnings.filterwarnings('ignore')\nDerive Price from Sales and Quantity: \\(Price=Sales/Quantity\\)\nAdd Week, Month, Year and YearMonth to dataframe"
  },
  {
    "objectID": "supermart analysis-regression - 9 nov.html#sales-pattern-analysis",
    "href": "supermart analysis-regression - 9 nov.html#sales-pattern-analysis",
    "title": "Price Demand Analysis on Retail Data",
    "section": "Sales Pattern Analysis",
    "text": "Sales Pattern Analysis\n\nOverall Level\n\nThere is yearly seasonal pattern observed and upward trend\n\n\n\nCode\ntotal_ym=df.groupby(['YearMonth'])['Sales'].agg(sum).reset_index()\nfig = px.line(total_ym, x='YearMonth', y=\"Sales\", markers=True)\nfig.update_layout(title_text='Total Sales vs Year Month', title_x=0.5)\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\ntotal_q_ym=df.groupby(['YearMonth'])['Quantity'].agg(sum).reset_index()\nfig = px.line(total_q_ym, x='YearMonth', y=\"Quantity\", markers=True)\nfig.update_layout(title_text='Total Quantitiy Sales vs Year Month', title_x=0.5)\nfig.show()\n\n\n\n                                                \n\n\n\nTime Series Decomposition\n\nTime series data has 3 components, trend, seasonal and residual\n\nTrend Component: There is upward trend present in the data\n\n\nCode\ntotal_q_ym_sd=total_q_ym\ntotal_q_ym_sd['YearMonth'] = pd.to_datetime(total_q_ym_sd['YearMonth'], format='%Y-%m')\ntotal_q_ym_sd = total_q_ym_sd.set_index('YearMonth')\ndecompose = seasonal_decompose(total_q_ym_sd.Quantity).trend.plot()\ndecompose.figure.set_size_inches(15, 2)\n\n\n\n\n\nSeasonal Component: There is yearly seasonality present in the data\n\n\nCode\ndecompose = seasonal_decompose(total_q_ym_sd.Quantity).seasonal.plot()\ndecompose.figure.set_size_inches(15, 2)\n\n\n\n\n\n\nThere is no pattern observed between Price and Quantity at overall level\n\n\n\nCode\ntotal_p_ym=df.groupby(['YearMonth']).agg({'Price':'mean','Quantity':'sum'}).reset_index()\nfig = px.scatter(total_p_ym, x='Quantity', y=\"Price\")\nfig.update_layout(title_text='Price vs Quantity for All Category', title_x=0.5)\nfig.show()\n\n\n\n                                                \n\n\n\n\n\nCategory Level\n\n\nCode\nprint ('Total quantiy sold:',df.Quantity.sum())\n\n\nTotal quantiy sold: 196173\n\n\n\nAll cateogries are contributing to ~15% of the total sales\n\n\n\nCode\ncat_sales=df.groupby(['Category'])['Quantity'].agg(sum).reset_index().sort_values(by='Quantity',ascending=False)\nfig = px.pie(cat_sales, values='Quantity', names='Category')\nfig.update_traces(textinfo='value+percent')\nfig.show()\n\n\n\n                                                \n\n\n\nCategory sales wrt year month\n\nOil and Masala has reduced in 2018 Q4 is performing better than rest of the quarters for all categories Fruits & Veggies sales reduced from 2016 to 2017\n\n\n\nCode\ncat_q_ym=df.groupby(['Category','YearMonth', 'Month'])['Quantity'].agg(sum).reset_index()\nfig = px.line(cat_q_ym, x='YearMonth', y=\"Quantity\", color='Category', facet_col=\"Category\",facet_col_wrap=4)\nfig.show()\n\n\n\n                                                \n\n\n\n\nInclude Trend and Seasonal indicator\n\nTrend is added by assigning 1 to first date and then incrementing it by 1 Seasonality is added by including month number\n\n\n\nCode\ntrend_df=df.groupby(['YearMonth','Month'])['Quantity'].agg(sum).reset_index()\ntrend_df['Trend']=pd.Series(range(1,trend_df.shape[0]+1))\ntrend_df[['YearMonth','Month','Trend']].head(15)\n\n\n\n\n\n\n  \n    \n      \n      YearMonth\n      Month\n      Trend\n    \n  \n  \n    \n      0\n      2015-01\n      1\n      1\n    \n    \n      1\n      2015-02\n      2\n      2\n    \n    \n      2\n      2015-03\n      3\n      3\n    \n    \n      3\n      2015-04\n      4\n      4\n    \n    \n      4\n      2015-05\n      5\n      5\n    \n    \n      5\n      2015-06\n      6\n      6\n    \n    \n      6\n      2015-07\n      7\n      7\n    \n    \n      7\n      2015-08\n      8\n      8\n    \n    \n      8\n      2015-09\n      9\n      9\n    \n    \n      9\n      2015-10\n      10\n      10\n    \n    \n      10\n      2015-11\n      11\n      11\n    \n    \n      11\n      2015-12\n      12\n      12\n    \n    \n      12\n      2016-01\n      1\n      13\n    \n    \n      13\n      2016-02\n      2\n      14\n    \n    \n      14\n      2016-03\n      3\n      15\n    \n  \n\n\n\n\n\n\nCorrelation plot\n\n\n\nSnacks, Bakery and Food Grains are highly correlated\n\n\nFruit & Veggies is highly correlated with Egg, Meat & Fish\n\n\nTrend component is around 0.5 for all the categories\n\n\nSeasonal component is correlated more with the category compared to trend component\n\n\n\n\n\nCode\ncat_q_ym\ncat_ym_q_pivot=pd.pivot_table(cat_q_ym, values ='Quantity', index =['YearMonth','Month'], columns =['Category'], aggfunc = np.sum).reset_index()\ncat_sales_ym=df.groupby(['YearMonth'])['Quantity'].agg(sum).reset_index()\ncat_ym_q_pivot=pd.merge(cat_ym_q_pivot, cat_sales_ym, on='YearMonth', how='left')\ncat_ym_q_pivot['Trend']=pd.Series(range(1,cat_ym_q_pivot.shape[0]+1))\n\ncorr_plot=np.round(cat_ym_q_pivot.corr(),2)\nmask=np.triu(np.ones_like(corr_plot, dtype=bool))\nf, ax = plt.subplots(figsize=(11, 9))\nsns.heatmap(corr_plot,mask=mask, \n#             cmap='PiYG',\n            cmap='Greens',\n            vmax=1, \n            vmin = 0.4,\n            annot = True)\nplt.title('Correlation Plot')\nplt.show()\n\n\n\n\n\n\n\nPrice vs Quantity\n\nAt category level there is no significant trend is observed. Slope of the line is close to 0\n\n\n\nCode\ntotal_p_ym=df.groupby(['Category','YearMonth']).agg({'Price':'mean','Quantity':'sum'}).reset_index()\n# fig = px.scatter(total_p_ym[total_p_ym['Category']=='Beverages'], x='Quantity', y=\"Price\")\nfig = px.scatter(total_p_ym, x='Quantity', y=\"Price\", color='Category' , trendline=\"ols\")\nfig.update_layout(title_text='Price vs Quantity for Category', title_x=0.5)\nfig.show()"
  },
  {
    "objectID": "supermart analysis-regression - 9 nov.html#regression-analysis",
    "href": "supermart analysis-regression - 9 nov.html#regression-analysis",
    "title": "Price Demand Analysis on Retail Data",
    "section": "Regression Analysis",
    "text": "Regression Analysis\n\nCategory Sales wrt to Sub Category Prices\n\nEquation: \\(Category Demand = const+coef_1*Price_{subcat1}+coef_2*Price_{subcat2}+coef_3*Price_{subcat3}+...\\)\n\n\n\nCode\ndef coefplot(results, Category_name):\n    '''\n    Takes in results of OLS model and returns a plot of \n    the coefficients with 95% confidence intervals.\n    \n    Removes intercept, so if uncentered will return error.\n    '''\n    # Create dataframe of results summary \n    coef_df = pd.DataFrame(results.summary().tables[1].data)\n    \n    # Add column names\n    coef_df.columns = coef_df.iloc[0]\n\n    # Drop the extra row with column labels\n    coef_df=coef_df.drop(0)\n\n    # Set index to variable names \n    coef_df = coef_df.set_index(coef_df.columns[0])\n\n    # Change datatype from object to float\n    coef_df = coef_df.astype(float)\n\n    # Get errors; (coef - lower bound of conf interval)\n    errors = coef_df['coef'] - coef_df['[0.025']\n    \n    # Append errors column to dataframe\n    coef_df['errors'] = errors\n\n    # Drop the constant for plotting\n    coef_df = coef_df.drop(['const'])\n\n    # Sort values by coef ascending\n    coef_df = coef_df.sort_values(by=['coef'])\n\n    ### Plot Coefficients ###\n\n    # x-labels\n    variables = list(coef_df.index.values)\n    \n    # Add variables column to dataframe\n    coef_df['variables'] = variables\n    \n    # Set sns plot style back to 'poster'\n    # This will make bars wide on plot\n    sns.set_context(\"poster\")\n\n    # Define figure, axes, and plot\n    fig, ax = plt.subplots(figsize=(10, 3))\n    \n    # Error bars for 95% confidence interval\n    # Can increase capsize to add whiskers\n    coef_df.plot(x='variables', y='coef', kind='bar',\n                 ax=ax, color='none', fontsize=10, \n                 ecolor='steelblue',capsize=0,\n                 yerr='errors', legend=False)\n    \n    # Set title & labels\n    plt.title(Category_name,fontsize=12)\n    ax.set_ylabel('Coefficients',fontsize=10)\n    ax.set_xlabel('',fontsize=10)\n    \n    # Coefficients\n    ax.scatter(x=pd.np.arange(coef_df.shape[0]), \n               marker='o', s=80, \n               y=coef_df['coef'], color='steelblue')\n    \n    # Line to define zero on the y-axis\n    ax.axhline(y=0, linestyle='--', color='red', linewidth=1)\n    \n    return plt.show()\n\n\n\nCoefficient Regression Plots for all the models\n\n\nCode\nCategory_ls=['Bakery', 'Beverages', 'Eggs, Meat & Fish', 'Food Grains', 'Fruits & Veggies', 'Oil & Masala', 'Snacks']\n\noutput=pd.DataFrame()\n\n# df_train=df[df['YearMonth']<'2018-09']\ndf_train=df\n\nsubcat_ym=df_train.groupby(['Category','Sub Category','YearMonth','Month']).agg({'Quantity':'sum','Price':'mean'}).reset_index()\ncat_ym=df_train.groupby(['Category','YearMonth']).agg({'Quantity':'sum'}).reset_index()\ncat_subcat_mapping=pd.DataFrame(df[['Category','Sub Category']].value_counts()).reset_index()\ncat_subcat_mapping=cat_subcat_mapping[['Category','Sub Category']]\n\n\nfor cat in Category_ls:\n    \n#     print(cat)\n    temp=pd.DataFrame()\n    subcat_ls=cat_subcat_mapping[cat_subcat_mapping['Category']==cat]['Sub Category'].tolist()\n    \n    subcat_p_ym_pivot=pd.pivot_table(subcat_ym[subcat_ym['Category']==cat], values ='Price', index =['YearMonth','Month'], columns =['Sub Category'], aggfunc = np.sum).reset_index()\n    subcat_p_ym_pivot['Trend']=pd.Series(range(1,subcat_p_ym_pivot.shape[0]+1))\n    qty_ym=cat_ym[cat_ym['Category']==cat][['YearMonth','Quantity']]\n    \n#     print(subcat_p_ym_pivot)\n    price_model_cat=pd.merge(subcat_p_ym_pivot,qty_ym,on='YearMonth',how='left')\n    price_model_cat=price_model_cat.fillna(price_model_cat.rolling(3, min_periods=1).mean().shift())\n#     print(price_model_cat)\n    price_model_cat_X = sm.add_constant(price_model_cat[['Month','Trend']+subcat_ls], prepend=False)\n    mod = sm.OLS(price_model_cat.Quantity, price_model_cat_X)\n    res = mod.fit()\n#     print(res.summary())\n    coefplot(res, cat)\n    temp['Variable']=res.model.exog_names\n    temp['Coefficient']=res.params.values\n    temp['Category']=cat \n    \n    output=output.append(temp, ignore_index=True)\n#     print(output)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noutput_coeff=output[['Category','Variable','Coefficient']].sort_values(by=['Category','Coefficient'], ascending=True)\n# .style.background_gradient(cmap='RdGy')\n# output_coeff\n\n\n\n\nRegression coeficient values in tabular format\n\n\nCode\ndf1_styler = output_coeff[output_coeff['Category']=='Bakery'][['Variable','Coefficient']].reset_index(drop=True).style.background_gradient(cmap='RdGy').set_table_attributes(\"style='display:inline'\").set_caption('Bakery')\ndf2_styler = output_coeff[output_coeff['Category']=='Beverages'][['Variable','Coefficient']].reset_index(drop=True).style.background_gradient(cmap='RdGy').set_table_attributes(\"style='display:inline'\").set_caption('Beverages')\ndf3_styler = output_coeff[output_coeff['Category']=='Eggs, Meat & Fish'][['Variable','Coefficient']].reset_index(drop=True).style.background_gradient(cmap='RdGy').set_table_attributes(\"style='display:inline'\").set_caption('Eggs, Meat & Fish')\ndf4_styler = output_coeff[output_coeff['Category']=='Food Grains'][['Variable','Coefficient']].reset_index(drop=True).style.background_gradient(cmap='RdGy').set_table_attributes(\"style='display:inline'\").set_caption('Food Grains')\ndf5_styler = output_coeff[output_coeff['Category']=='Fruits & Veggies'][['Variable','Coefficient']].reset_index(drop=True).style.background_gradient(cmap='RdGy').set_table_attributes(\"style='display:inline'\").set_caption('Fruits & Veggies')\ndf6_styler = output_coeff[output_coeff['Category']=='Oil & Masala'][['Variable','Coefficient']].reset_index(drop=True).style.background_gradient(cmap='RdGy').set_table_attributes(\"style='display:inline'\").set_caption('Oil & Masala')\ndf7_styler = output_coeff[output_coeff['Category']=='Snacks'][['Variable','Coefficient']].reset_index(drop=True).style.background_gradient(cmap='RdGy').set_table_attributes(\"style='display:inline'\").set_caption('Snacks')\n\n\nspace = \"\\xa0\" * 10\ndisplay_html(df1_styler._repr_html_()+space+df2_styler._repr_html_()+space+df3_styler._repr_html_()+space+df4_styler._repr_html_()+space+df5_styler._repr_html_()+space+df6_styler._repr_html_()+space+df7_styler._repr_html_(), raw=True)\n# display_html(df5_styler._repr_html_()+space+df6_styler._repr_html_()+space+df7_styler._repr_html_(), raw=True)\n\n\n\n\n\n  Bakery\n  \n    \n       \n      Variable\n      Coefficient\n    \n  \n  \n    \n      0\n      Breads & Buns\n      -1.086242\n    \n    \n      1\n      Cakes\n      -0.251251\n    \n    \n      2\n      Biscuits\n      -0.082141\n    \n    \n      3\n      Trend\n      8.894311\n    \n    \n      4\n      Month\n      65.746638\n    \n    \n      5\n      const\n      140.539283\n    \n  \n\n          \n\n  Beverages\n  \n    \n       \n      Variable\n      Coefficient\n    \n  \n  \n    \n      0\n      Health Drinks\n      -0.965430\n    \n    \n      1\n      Soft Drinks\n      -0.290544\n    \n    \n      2\n      Trend\n      8.381029\n    \n    \n      3\n      Month\n      46.494121\n    \n    \n      4\n      const\n      250.300922\n    \n  \n\n          \n\n  Eggs, Meat & Fish\n  \n    \n       \n      Variable\n      Coefficient\n    \n  \n  \n    \n      0\n      Eggs\n      -0.706483\n    \n    \n      1\n      Chicken\n      -0.554023\n    \n    \n      2\n      Mutton\n      -0.117788\n    \n    \n      3\n      Fish\n      0.049169\n    \n    \n      4\n      Trend\n      11.065731\n    \n    \n      5\n      Month\n      60.206332\n    \n    \n      6\n      const\n      130.620098\n    \n  \n\n          \n\n  Food Grains\n  \n    \n       \n      Variable\n      Coefficient\n    \n  \n  \n    \n      0\n      Organic Staples\n      -0.429108\n    \n    \n      1\n      Rice\n      -0.181652\n    \n    \n      2\n      Dals & Pulses\n      -0.065190\n    \n    \n      3\n      Atta & Flour\n      0.093873\n    \n    \n      4\n      Trend\n      10.595552\n    \n    \n      5\n      const\n      26.955690\n    \n    \n      6\n      Month\n      57.703610\n    \n  \n\n          \n\n  Fruits & Veggies\n  \n    \n       \n      Variable\n      Coefficient\n    \n  \n  \n    \n      0\n      const\n      -9.137286\n    \n    \n      1\n      Fresh Vegetables\n      -0.223045\n    \n    \n      2\n      Fresh Fruits\n      -0.125664\n    \n    \n      3\n      Organic Fruits\n      -0.112682\n    \n    \n      4\n      Organic Vegetables\n      0.460909\n    \n    \n      5\n      Trend\n      8.570907\n    \n    \n      6\n      Month\n      60.829556\n    \n  \n\n          \n\n  Oil & Masala\n  \n    \n       \n      Variable\n      Coefficient\n    \n  \n  \n    \n      0\n      Masalas\n      -0.727665\n    \n    \n      1\n      Spices\n      -0.120953\n    \n    \n      2\n      Edible Oil & Ghee\n      0.280271\n    \n    \n      3\n      Trend\n      8.577789\n    \n    \n      4\n      Month\n      47.300495\n    \n    \n      5\n      const\n      128.184998\n    \n  \n\n          \n\n  Snacks\n  \n    \n       \n      Variable\n      Coefficient\n    \n  \n  \n    \n      0\n      Chocolates\n      -0.889797\n    \n    \n      1\n      Noodles\n      -0.763125\n    \n    \n      2\n      Cookies\n      -0.062719\n    \n    \n      3\n      Trend\n      12.724632\n    \n    \n      4\n      Month\n      56.185318\n    \n    \n      5\n      const\n      230.839103\n    \n  \n\n\n\n\n\nPrediction\n\n\nCode\npred_df[['Category','YearMonth','Actual','Predicted']]\n\n\n\n\n\n\n  \n    \n      \n      Category\n      YearMonth\n      Actual\n      Predicted\n    \n  \n  \n    \n      0\n      Bakery\n      2018-09\n      1176\n      793.884786\n    \n    \n      1\n      Bakery\n      2018-10\n      948\n      907.289841\n    \n    \n      2\n      Bakery\n      2018-11\n      1336\n      1025.692555\n    \n    \n      3\n      Bakery\n      2018-12\n      1144\n      987.300701\n    \n    \n      4\n      Beverages\n      2018-09\n      1064\n      764.340078\n    \n    \n      5\n      Beverages\n      2018-10\n      749\n      737.847580\n    \n    \n      6\n      Beverages\n      2018-11\n      1203\n      866.662852\n    \n    \n      7\n      Beverages\n      2018-12\n      1415\n      856.015880\n    \n    \n      8\n      Eggs, Meat & Fish\n      2018-09\n      1699\n      880.098797\n    \n    \n      9\n      Eggs, Meat & Fish\n      2018-10\n      697\n      942.236007\n    \n    \n      10\n      Eggs, Meat & Fish\n      2018-11\n      1029\n      1007.953825\n    \n    \n      11\n      Eggs, Meat & Fish\n      2018-12\n      1430\n      1052.338362\n    \n    \n      12\n      Food Grains\n      2018-09\n      1316\n      859.628290\n    \n    \n      13\n      Food Grains\n      2018-10\n      865\n      1004.396308\n    \n    \n      14\n      Food Grains\n      2018-11\n      1348\n      898.473128\n    \n    \n      15\n      Food Grains\n      2018-12\n      1052\n      1086.605885\n    \n    \n      16\n      Fruits & Veggies\n      2018-09\n      1237\n      807.159613\n    \n    \n      17\n      Fruits & Veggies\n      2018-10\n      849\n      896.061309\n    \n    \n      18\n      Fruits & Veggies\n      2018-11\n      1163\n      952.495670\n    \n    \n      19\n      Fruits & Veggies\n      2018-12\n      1501\n      1090.346768\n    \n    \n      20\n      Oil & Masala\n      2018-09\n      1023\n      823.730382\n    \n    \n      21\n      Oil & Masala\n      2018-10\n      798\n      885.632846\n    \n    \n      22\n      Oil & Masala\n      2018-11\n      1232\n      925.337395\n    \n    \n      23\n      Oil & Masala\n      2018-12\n      1205\n      986.035445\n    \n    \n      24\n      Snacks\n      2018-09\n      1478\n      931.136825\n    \n    \n      25\n      Snacks\n      2018-10\n      724\n      894.805078\n    \n    \n      26\n      Snacks\n      2018-11\n      1832\n      1108.481441\n    \n    \n      27\n      Snacks\n      2018-12\n      1276\n      1090.186614\n    \n  \n\n\n\n\n\n\nCategory level MAPE\nEquation: \\(MAPE = mean(abs((actual-predicted)/actual))\\)\n\n\nCode\npred_df.groupby(['Category']).MAPE.mean().reset_index().sort_values('MAPE')\n\n\n\n\n\n\n  \n    \n      \n      Category\n      MAPE\n    \n  \n  \n    \n      5\n      Oil & Masala\n      18.380821\n    \n    \n      0\n      Bakery\n      18.427802\n    \n    \n      4\n      Fruits & Veggies\n      21.437630\n    \n    \n      3\n      Food Grains\n      21.857776\n    \n    \n      1\n      Beverages\n      24.278720\n    \n    \n      2\n      Eggs, Meat & Fish\n      27.959681\n    \n    \n      6\n      Snacks\n      28.661906\n    \n  \n\n\n\n\n\n\n\nSub Category Demand wrt to its Price\n\nEquation: \\(Subcat Demand = Coef * Price + constant\\)\n\n\n\nCode\nCategory_ls=['Bakery', 'Beverages', 'Eggs, Meat & Fish', 'Food Grains', 'Fruits & Veggies', 'Oil & Masala', 'Snacks']\n\noutput=pd.DataFrame()\n\n# df_train=df[df['YearMonth']<'2018-09']\ndf_train=df\n\nsubcat_ym=df_train.groupby(['Category','Sub Category','YearMonth','Month']).agg({'Quantity':'sum','Price':'mean'}).reset_index()\ncat_ym=df_train.groupby(['Category','YearMonth']).agg({'Quantity':'sum'}).reset_index()\ncat_subcat_mapping=pd.DataFrame(df[['Category','Sub Category']].value_counts()).reset_index()\ncat_subcat_mapping=cat_subcat_mapping[['Category','Sub Category']]\n\n\nfor cat in Category_ls:\n    \n#     print(cat)\n    \n    subcat_ls=cat_subcat_mapping[cat_subcat_mapping['Category']==cat]['Sub Category'].tolist()\n    \n    for subcat in subcat_ls:\n#         print(subcat)\n        temp=pd.DataFrame()\n        subcat_p_ym_t=subcat_ym[subcat_ym['Sub Category']==subcat]\n#         print(subcat_p_ym_t)\n            \n        subcat_p_ym_t['Trend']=pd.Series(range(1,subcat_p_ym_t.shape[0]+1)).values\n    \n        subcat_p_ym_t=subcat_p_ym_t.fillna(subcat_p_ym_t.rolling(3, min_periods=1).mean().shift())\n        subcat_p_ym_t_X = sm.add_constant(subcat_p_ym_t[['Price','Month','Trend']], prepend=False)\n        mod = sm.OLS(subcat_p_ym_t.Quantity, subcat_p_ym_t_X)\n        res = mod.fit()\n#         print(res.summary())\n    \n        temp['Variable']=res.model.exog_names\n        temp['Coefficient']=res.params.values\n        temp['Category']=cat \n        temp['Sub Category']=subcat\n        output=output.append(temp, ignore_index=True)\n#     print(output)\n\n\n\n\nCode\noutput[output['Variable']=='Price'][['Category','Sub Category','Variable','Coefficient']].sort_values(by='Coefficient', ascending=True).style.background_gradient(cmap='RdYlGn')\n\n\n\n\n\n  \n    \n       \n      Category\n      Sub Category\n      Variable\n      Coefficient\n    \n  \n  \n    \n      80\n      Snacks\n      Cookies\n      Price\n      -0.674563\n    \n    \n      0\n      Bakery\n      Breads & Buns\n      Price\n      -0.633320\n    \n    \n      88\n      Snacks\n      Noodles\n      Price\n      -0.556082\n    \n    \n      68\n      Oil & Masala\n      Masalas\n      Price\n      -0.488256\n    \n    \n      12\n      Beverages\n      Health Drinks\n      Price\n      -0.402775\n    \n    \n      84\n      Snacks\n      Chocolates\n      Price\n      -0.383040\n    \n    \n      24\n      Eggs, Meat & Fish\n      Eggs\n      Price\n      -0.345920\n    \n    \n      20\n      Eggs, Meat & Fish\n      Mutton\n      Price\n      -0.319583\n    \n    \n      64\n      Fruits & Veggies\n      Organic Vegetables\n      Price\n      -0.298968\n    \n    \n      36\n      Food Grains\n      Organic Staples\n      Price\n      -0.293816\n    \n    \n      44\n      Food Grains\n      Dals & Pulses\n      Price\n      -0.202027\n    \n    \n      8\n      Bakery\n      Cakes\n      Price\n      -0.196595\n    \n    \n      16\n      Beverages\n      Soft Drinks\n      Price\n      -0.178806\n    \n    \n      32\n      Eggs, Meat & Fish\n      Chicken\n      Price\n      -0.164009\n    \n    \n      56\n      Fruits & Veggies\n      Fresh Vegetables\n      Price\n      -0.157494\n    \n    \n      76\n      Oil & Masala\n      Spices\n      Price\n      -0.097857\n    \n    \n      60\n      Fruits & Veggies\n      Organic Fruits\n      Price\n      -0.092019\n    \n    \n      52\n      Fruits & Veggies\n      Fresh Fruits\n      Price\n      -0.083300\n    \n    \n      28\n      Eggs, Meat & Fish\n      Fish\n      Price\n      -0.074796\n    \n    \n      48\n      Food Grains\n      Rice\n      Price\n      -0.062922\n    \n    \n      40\n      Food Grains\n      Atta & Flour\n      Price\n      -0.034715\n    \n    \n      72\n      Oil & Masala\n      Edible Oil & Ghee\n      Price\n      0.020378\n    \n    \n      4\n      Bakery\n      Biscuits\n      Price\n      0.025511\n    \n  \n\n\n\n\n\nCode\nimport nbdev; nbdev.nbdev_export()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analytics Series",
    "section": "",
    "text": "Here we are doing a series on Data Analystics using a reatils data set taken from Kaggle.\nHere are the notebooks for two session done till now\n\nSession 1 : Customer Analysis using RFM models <Link here>\nSession 2 : Sales Analysis via Regression Models <Link here>\n\nA brief about the data is as follows"
  },
  {
    "objectID": "index.html#you-can-do-and-add-you-analysis-using-follwing-steps",
    "href": "index.html#you-can-do-and-add-you-analysis-using-follwing-steps",
    "title": "Data Analytics Series",
    "section": "You can do and add you analysis using follwing steps",
    "text": "You can do and add you analysis using follwing steps\nPre-requisite: You need to have a github account\nSteps:\n1. Use Cmd Shell to create a new python environment using conda or venv, and install relevnat packages for you analysis.\n2. Install nbdev. Make sure you use pip install --force-reinstall nbdev to install this.\n3. Clone this repository via git clone https://github.com/jkapila/retail-analytics.git\n4. Get in folder using cd retail-analytics\\nbs.\n5. Create a new branch with your name, like yourname-analysis.\n6. Open jupyter lab / notebook in folder and add notebook with a sequence identifier as XX_Name_of_Notebook.ipynb.\n7. Keep working in the notebook wiht all you analysis.\n8. After the work is finish run nbdev_prepare\n9. Git add, commit and push.\n10. Create a PR to add you analysis."
  },
  {
    "objectID": "index.html#analysis-and-queries",
    "href": "index.html#analysis-and-queries",
    "title": "Data Analytics Series",
    "section": "Analysis and Queries",
    "text": "Analysis and Queries\n\nTo use the analysis you can go through the notebook in cronological order if number XX\n\nFor any doubts please connect or refer documnetation on nbdev."
  },
  {
    "objectID": "rfm.html",
    "href": "rfm.html",
    "title": "Customer related Analysis for our data",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport squarify\nimport plotly.express as px\n\n\n\n\nCode\ndf=pd.read_csv(\"C:/Users/vipulchopra/EDA/Supermart_Dataset.csv\")\ndf.head()\n\n\n\n\n\n\n  \n    \n      \n      Order ID\n      Customer Name\n      Customer Id\n      Age\n      Gender\n      Category\n      Sub Category\n      Region\n      State\n      City\n      Order Date\n      Time\n      Payment Method\n      Sales\n      Quantity\n      Discount\n      Profit\n      Rating\n    \n  \n  \n    \n      0\n      OD1\n      Harish\n      13\n      53\n      Male\n      Oil & Masala\n      Masalas\n      North\n      Tamil Nadu\n      Vellore\n      2017-11-08\n      13:03:25\n      Cash\n      1254\n      7\n      0.12\n      401.28\n      8.0\n    \n    \n      1\n      OD2\n      Sudha\n      38\n      31\n      Female\n      Beverages\n      Health Drinks\n      South\n      Tamil Nadu\n      Krishnagiri\n      2017-11-08\n      12:09:46\n      Cash\n      749\n      14\n      0.18\n      149.80\n      1.0\n    \n    \n      2\n      OD3\n      Hussain\n      15\n      18\n      Male\n      Food Grains\n      Atta & Flour\n      West\n      Tamil Nadu\n      Perambalur\n      2017-06-12\n      14:14:10\n      Credit card\n      2360\n      22\n      0.21\n      165.20\n      1.0\n    \n    \n      3\n      OD4\n      Jackson\n      16\n      69\n      Male\n      Fruits & Veggies\n      Fresh Vegetables\n      South\n      Tamil Nadu\n      Dharmapuri\n      2016-10-11\n      09:22:01\n      Cash\n      896\n      13\n      0.25\n      89.60\n      8.0\n    \n    \n      4\n      OD5\n      Ridhesh\n      29\n      12\n      Male\n      Food Grains\n      Organic Staples\n      South\n      Tamil Nadu\n      Ooty\n      2016-10-11\n      17:01:25\n      Ewallet\n      2355\n      8\n      0.26\n      918.45\n      9.0\n    \n  \n\n\n\n\n\nDefining the RFM terminologies as:\n\nThe more recent they purchase, the more responsive the customers are i.e recent purchase = low recency value.\nThe more frequently the customers buy, the more engaged and satisfied they are i.e high frequency = high f value.\nThe more they spend, the higher their monetary value.\n\n\n\nCode\ndf['Unit Sale Price']=round(df['Sales']/df['Quantity'],2)\ndf[\"Order Date\"]=pd.to_datetime(df[\"Order Date\"])\n\n\n\n\nCalculating the Recency , considering the last date of “Order Date” as reference\n\n\nCode\nRecency = pd.DataFrame(df.groupby('Customer Id')['Order Date'].max().reset_index())\nRecency['Recency'] = (Recency['Order Date'].max() - Recency['Order Date']).dt.days + 1\nRecency.head()\n\n\n\n\n\n\n  \n    \n      \n      Customer Id\n      Order Date\n      Recency\n    \n  \n  \n    \n      0\n      1\n      2018-12-23\n      8\n    \n    \n      1\n      2\n      2018-12-29\n      2\n    \n    \n      2\n      3\n      2018-12-28\n      3\n    \n    \n      3\n      4\n      2018-12-24\n      7\n    \n    \n      4\n      5\n      2018-12-27\n      4\n    \n  \n\n\n\n\n\n\nCalculating the Frequency for every Customer Id\n\n\nCode\nFrequency = pd.DataFrame(df.groupby('Customer Id')['Order ID'].nunique(). reset_index())\nFrequency.columns= ['fCustomer Id', 'Frequency']\nFrequency.head()\n\n\n\n\n\n\n  \n    \n      \n      fCustomer Id\n      Frequency\n    \n  \n  \n    \n      0\n      1\n      205\n    \n    \n      1\n      2\n      187\n    \n    \n      2\n      3\n      196\n    \n    \n      3\n      4\n      198\n    \n    \n      4\n      5\n      227\n    \n  \n\n\n\n\n\n\nCalculating the MonetaryValue , by considering the profit received by a customer in the whole data tenure\n\n\nCode\nMonetaryValue = pd.DataFrame(df.groupby('Customer Id')['Profit'].sum(). reset_index())\nMonetaryValue.columns= ['mCustomer Id', 'MonetaryValue']\nMonetaryValue.head()\n\n\n\n\n\n\n  \n    \n      \n      mCustomer Id\n      MonetaryValue\n    \n  \n  \n    \n      0\n      1\n      78044.29\n    \n    \n      1\n      2\n      78439.05\n    \n    \n      2\n      3\n      82121.26\n    \n    \n      3\n      4\n      74410.23\n    \n    \n      4\n      5\n      80191.89\n    \n  \n\n\n\n\n\n\nConcating the Recency,Frequency, MonetaryValue for unique Customer\n\n\nCode\nrfm = pd.concat([Recency, Frequency, MonetaryValue], axis=1)\nrfm.drop(['fCustomer Id', 'mCustomer Id','Order Date'], axis=1, inplace= True)\nrfm.head()\n\n\n\n\n\n\n  \n    \n      \n      Customer Id\n      Recency\n      Frequency\n      MonetaryValue\n    \n  \n  \n    \n      0\n      1\n      8\n      205\n      78044.29\n    \n    \n      1\n      2\n      2\n      187\n      78439.05\n    \n    \n      2\n      3\n      3\n      196\n      82121.26\n    \n    \n      3\n      4\n      7\n      198\n      74410.23\n    \n    \n      4\n      5\n      4\n      227\n      80191.89\n    \n  \n\n\n\n\n\n\nVisualization of RFM data per Customer Id\n\n\nCode\nplt.figure(figsize=(15.0,5.0))\nsns.barplot(data=rfm,x='Customer Id',y='Recency')\n\n\n<AxesSubplot:xlabel='Customer Id', ylabel='Recency'>\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(15.0,5.0))\nsns.barplot(data=rfm,x='Customer Id',y='Frequency')\n\n\n<AxesSubplot:xlabel='Customer Id', ylabel='Frequency'>\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(15.0,5.0))\nsns.barplot(data=rfm,x='Customer Id',y='MonetaryValue')\n\n\n<AxesSubplot:xlabel='Customer Id', ylabel='MonetaryValue'>\n\n\n\n\n\n\n\nRanking the Data, segmenting the data into 4 groups from 1 to 4\n\n\nCode\nr_labels = range(4, 0, -1);\nf_labels = range(1, 5);\nm_labels = range(1, 5)\n\nr_groups = pd.qcut(rfm['Recency'].rank(method='first'), q=4, labels=r_labels)\nf_groups = pd.qcut(rfm['Frequency'].rank(method='first'), q=4, labels=f_labels)\nm_groups = pd.qcut(rfm['MonetaryValue'].rank(method='first'), q=4, labels=m_labels)\n\n# Create new columns for R.F.M\nrfm_seg = rfm.assign(R = r_groups.values, F = f_groups.values,  M = m_groups.values)\n\n# concatenate RFM quartile values\nrfm_seg['RfmSegment'] = rfm_seg['R'].astype(str) + rfm_seg['F'].astype(str) + rfm_seg['M'].astype(str)\n\n\n\n\nCategorization of labels are as below:\n\nChampions : Bought recently, buy often and spend the most!\nLoyal Customers : Spend good money with us often.\nPotential Loyalist : Recent customers, but spent a good amount and bought more than once.\nRecent Customers : Bought most recently, but not often.\nPromising : Recent shoppers, but haven’t spent much.\nCustomers Needing Attention : Above average recency, frequency and monetary values.\nCan’t Lose Them : Made biggest purchases, and often. But haven’t returned for a long time. Need to bring them back!\nHibernating : Last purchase was long back, low spenders and bought seldomly. Will lose them if not reactivated.\nLost : Lowest recency, frequency and monetary scores (RFM score).\n\n\n\nCode\n# define users rfm category, using the RfmSegment column\n# logic is defined by business usually but here taking randomly\ndef users_cat(seg):\n      if seg['RfmSegment'] == '444':\n        return 'Champions'\n\n      elif seg['RfmSegment'] == '111':\n        return 'Lost'\n\n      else:\n        if seg['M'] == 4 & seg['F'] == 4: \n              return 'Loyal Customers'\n\n        if  seg['M'] == 4 & seg['F'] >= 3 & seg['R'] == 1:\n              return 'Cant Lose Them'\n\n        if seg['R'] >= 3 & seg['F'] <= 2:\n              return 'Recent Customers'\n\n        if seg['R'] >= 3 & seg['M'] <= 2:\n              return 'Promising'\n\n        if seg['R'] >= 3 & seg['M'] >= 3 & seg['F'] >= 1 | seg['F'] <= 2:\n              return 'Potential Loyalist'\n\n        if seg['R'] >=2 & seg['M'] >= 2 & seg['F'] >= 2:\n              return 'Customers Needing Attention'\n\n        return 'Hibernating'\n\nrfm_seg['RfmCat'] = rfm_seg.apply(users_cat, axis=1)\nrfm_seg.sample(5)\n\n\n\n\n\n\n  \n    \n      \n      Customer Id\n      Recency\n      Frequency\n      MonetaryValue\n      R\n      F\n      M\n      RfmSegment\n      RfmCat\n    \n  \n  \n    \n      1\n      2\n      2\n      187\n      78439.05\n      4\n      1\n      4\n      414\n      Recent Customers\n    \n    \n      11\n      12\n      3\n      174\n      64037.35\n      3\n      1\n      1\n      311\n      Recent Customers\n    \n    \n      18\n      19\n      9\n      206\n      76165.17\n      1\n      4\n      3\n      143\n      Recent Customers\n    \n    \n      40\n      41\n      2\n      209\n      80996.85\n      4\n      4\n      4\n      444\n      Champions\n    \n    \n      25\n      26\n      6\n      197\n      66970.60\n      2\n      2\n      1\n      221\n      Recent Customers\n    \n  \n\n\n\n\n\n\nCode\n# calculate the recency, frequency and monetary value mean, to see each category contribution\nrfm_agg = rfm_seg.groupby(['RfmCat']).agg({'Recency': 'mean',\n                                            'Frequency': 'mean',\n                                            'MonetaryValue': ['mean', 'count']}).round(0)\nrfm_agg.columns = rfm_agg.columns.droplevel()\n\nrfm_agg.columns =['Recency mean', 'Frequency mean', 'MonetaryValue mean', 'counts']\nrfm_agg['Percent'] = round((rfm_agg['counts']/ rfm_agg.counts.sum()) *100, 2)\nrfm_agg = rfm_agg.reset_index()\nrfm_agg\n\n\n\n\n\n\n  \n    \n      \n      RfmCat\n      Recency mean\n      Frequency mean\n      MonetaryValue mean\n      counts\n      Percent\n    \n  \n  \n    \n      0\n      Champions\n      2.0\n      209.0\n      80997.0\n      1\n      2.0\n    \n    \n      1\n      Customers Needing Attention\n      3.0\n      203.0\n      76809.0\n      5\n      10.0\n    \n    \n      2\n      Hibernating\n      8.0\n      199.0\n      75339.0\n      5\n      10.0\n    \n    \n      3\n      Lost\n      10.0\n      185.0\n      69526.0\n      3\n      6.0\n    \n    \n      4\n      Loyal Customers\n      4.0\n      218.0\n      83055.0\n      6\n      12.0\n    \n    \n      5\n      Promising\n      6.0\n      202.0\n      74864.0\n      7\n      14.0\n    \n    \n      6\n      Recent Customers\n      4.0\n      195.0\n      72801.0\n      23\n      46.0\n    \n  \n\n\n\n\n\n\nCode\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(20, 15)\n\ncolors_dict = {'Hibernating':'yellow','Promising':'royalblue',\n               'Lost':'red', 'Champions':'green', 'Loyal Customers':'gold', 'Customers Needing Attention':'grey', 'Recent Customers': 'purple'}\n\nsquarify.plot(sizes = rfm_agg['counts'],\n              text_kwargs = {'fontsize':16,'weight':'bold', 'fontname':'sans serif'},\n              color=colors_dict.values(),\n              label=['{} \\n{:.0f} days \\n{:.0f} purchase \\n${:.0f} \\n{:.0f} customers ({}%)'.format(*rfm_agg.iloc[i])\n                      for i in range(0, len(rfm_agg))], alpha=0.9 )\n\n\nplt.title('Customers Segments Using RFMmethod', fontsize=14, fontweight = 'bold')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\nCode\n#Profit value mean per per category\n\nrfm_agg['Profit_per_category']=round(rfm_agg['MonetaryValue mean']/(rfm_agg['Recency mean']*rfm_agg['Frequency mean']))#rfm_agg['counts'])\nrfm_agg\n\n\n\n\n\n\n  \n    \n      \n      RfmCat\n      Recency mean\n      Frequency mean\n      MonetaryValue mean\n      counts\n      Percent\n      Profit_per_category\n    \n  \n  \n    \n      0\n      Champions\n      2.0\n      209.0\n      80997.0\n      1\n      2.0\n      194.0\n    \n    \n      1\n      Customers Needing Attention\n      3.0\n      203.0\n      76809.0\n      5\n      10.0\n      126.0\n    \n    \n      2\n      Hibernating\n      8.0\n      199.0\n      75339.0\n      5\n      10.0\n      47.0\n    \n    \n      3\n      Lost\n      10.0\n      185.0\n      69526.0\n      3\n      6.0\n      38.0\n    \n    \n      4\n      Loyal Customers\n      4.0\n      218.0\n      83055.0\n      6\n      12.0\n      95.0\n    \n    \n      5\n      Promising\n      6.0\n      202.0\n      74864.0\n      7\n      14.0\n      62.0\n    \n    \n      6\n      Recent Customers\n      4.0\n      195.0\n      72801.0\n      23\n      46.0\n      93.0\n    \n  \n\n\n\n\n\n\nChecking a business Scenario, whether is it profitable to move a lower segment customer into higher segment?\n\n\nCode\n#Considering the cost to convert  the same is per customer is 500.\n#taking conversion ratio as 20%\ncategory=[\"Champions\",\"Loyal Customers\",\"Recent Customers\",\"Promising\",\"Customers Needing Attention\",\"Hibernating\",\"Lost\"]\nt=[]\nfor i in range(1,len(category)):\n    for j in range(i):\n        t.append([category[i],category[j]])\nt\n\n\n[['Loyal Customers', 'Champions'],\n ['Recent Customers', 'Champions'],\n ['Recent Customers', 'Loyal Customers'],\n ['Promising', 'Champions'],\n ['Promising', 'Loyal Customers'],\n ['Promising', 'Recent Customers'],\n ['Customers Needing Attention', 'Champions'],\n ['Customers Needing Attention', 'Loyal Customers'],\n ['Customers Needing Attention', 'Recent Customers'],\n ['Customers Needing Attention', 'Promising'],\n ['Hibernating', 'Champions'],\n ['Hibernating', 'Loyal Customers'],\n ['Hibernating', 'Recent Customers'],\n ['Hibernating', 'Promising'],\n ['Hibernating', 'Customers Needing Attention'],\n ['Lost', 'Champions'],\n ['Lost', 'Loyal Customers'],\n ['Lost', 'Recent Customers'],\n ['Lost', 'Promising'],\n ['Lost', 'Customers Needing Attention'],\n ['Lost', 'Hibernating']]\n\n\n\n\nCode\nNet_Profit=[]\nfor i in t:\n    profit_conversion=list(rfm_agg[rfm_agg['RfmCat']==i[1]]['MonetaryValue mean'])[0]-list(rfm_agg[rfm_agg['RfmCat']==i[0]]['MonetaryValue mean'])[0]\n    Net_Profit.append(profit_conversion*0.2*list(rfm_agg[rfm_agg['RfmCat']==i[0]]['counts'])[0]-500*list(rfm_agg[rfm_agg['RfmCat']==i[0]]['counts'])[0])\nNet_Profit\n\n\n[-5469.6,\n 26201.6,\n 35668.4,\n 5086.200000000001,\n 7967.4,\n -6388.200000000001,\n 1688.0,\n 3746.0,\n -6508.0,\n -4445.0,\n 3158.000000000001,\n 5216.0,\n -5038.0,\n -2975.0,\n -1030.0,\n 5382.6,\n 6617.400000000001,\n 465.0,\n 1702.8000000000002,\n 2869.8,\n 1987.8000000000002]\n\n\n\n\nCode\ntotal=[]\nfor i in range(len(t)):\n    t[i].append(Net_Profit[i])\n    total.append(t[i])\nx=pd.DataFrame(total,columns=[\"From\",\"To\",\"Profit\"])\nx\n\n\n\n\n\n\n  \n    \n      \n      From\n      To\n      Profit\n    \n  \n  \n    \n      0\n      Loyal Customers\n      Champions\n      -5469.6\n    \n    \n      1\n      Recent Customers\n      Champions\n      26201.6\n    \n    \n      2\n      Recent Customers\n      Loyal Customers\n      35668.4\n    \n    \n      3\n      Promising\n      Champions\n      5086.2\n    \n    \n      4\n      Promising\n      Loyal Customers\n      7967.4\n    \n    \n      5\n      Promising\n      Recent Customers\n      -6388.2\n    \n    \n      6\n      Customers Needing Attention\n      Champions\n      1688.0\n    \n    \n      7\n      Customers Needing Attention\n      Loyal Customers\n      3746.0\n    \n    \n      8\n      Customers Needing Attention\n      Recent Customers\n      -6508.0\n    \n    \n      9\n      Customers Needing Attention\n      Promising\n      -4445.0\n    \n    \n      10\n      Hibernating\n      Champions\n      3158.0\n    \n    \n      11\n      Hibernating\n      Loyal Customers\n      5216.0\n    \n    \n      12\n      Hibernating\n      Recent Customers\n      -5038.0\n    \n    \n      13\n      Hibernating\n      Promising\n      -2975.0\n    \n    \n      14\n      Hibernating\n      Customers Needing Attention\n      -1030.0\n    \n    \n      15\n      Lost\n      Champions\n      5382.6\n    \n    \n      16\n      Lost\n      Loyal Customers\n      6617.4\n    \n    \n      17\n      Lost\n      Recent Customers\n      465.0\n    \n    \n      18\n      Lost\n      Promising\n      1702.8\n    \n    \n      19\n      Lost\n      Customers Needing Attention\n      2869.8\n    \n    \n      20\n      Lost\n      Hibernating\n      1987.8\n    \n  \n\n\n\n\n\n\nCode\ndef even_number_background(cell_value):\n    highlight = 'background-color: #7FFFD4;' \n    \n    default = 'background-color: #FA8072;'  \n    if type(cell_value) in [float]:  \n        if cell_value > 0:     \n            return highlight  \n        else:\n            \n            return default\nx.style.applymap(even_number_background)\n\n\n\n\n\n  \n    \n       \n      From\n      To\n      Profit\n    \n  \n  \n    \n      0\n      Loyal Customers\n      Champions\n      -5469.600000\n    \n    \n      1\n      Recent Customers\n      Champions\n      26201.600000\n    \n    \n      2\n      Recent Customers\n      Loyal Customers\n      35668.400000\n    \n    \n      3\n      Promising\n      Champions\n      5086.200000\n    \n    \n      4\n      Promising\n      Loyal Customers\n      7967.400000\n    \n    \n      5\n      Promising\n      Recent Customers\n      -6388.200000\n    \n    \n      6\n      Customers Needing Attention\n      Champions\n      1688.000000\n    \n    \n      7\n      Customers Needing Attention\n      Loyal Customers\n      3746.000000\n    \n    \n      8\n      Customers Needing Attention\n      Recent Customers\n      -6508.000000\n    \n    \n      9\n      Customers Needing Attention\n      Promising\n      -4445.000000\n    \n    \n      10\n      Hibernating\n      Champions\n      3158.000000\n    \n    \n      11\n      Hibernating\n      Loyal Customers\n      5216.000000\n    \n    \n      12\n      Hibernating\n      Recent Customers\n      -5038.000000\n    \n    \n      13\n      Hibernating\n      Promising\n      -2975.000000\n    \n    \n      14\n      Hibernating\n      Customers Needing Attention\n      -1030.000000\n    \n    \n      15\n      Lost\n      Champions\n      5382.600000\n    \n    \n      16\n      Lost\n      Loyal Customers\n      6617.400000\n    \n    \n      17\n      Lost\n      Recent Customers\n      465.000000\n    \n    \n      18\n      Lost\n      Promising\n      1702.800000\n    \n    \n      19\n      Lost\n      Customers Needing Attention\n      2869.800000\n    \n    \n      20\n      Lost\n      Hibernating\n      1987.800000\n    \n  \n\n\n\n\n\nCode\nProfit=[]\nLoss=[]\nfor i in range(len(t)):\n    if Net_Profit[i]>0:\n        #t[i].append(Net_Profit[i])\n        Profit.append(t[i])\n    else:\n        #t[i].append(Net_Profit[i])\n        Loss.append(t[i])\n\n\n\n\nCode\nprofit=pd.DataFrame(Profit,columns=[\"From\",\"To\",\"Profit\"])\nprofit\n\n\n\n\n\n\n  \n    \n      \n      From\n      To\n      Profit\n    \n  \n  \n    \n      0\n      Recent Customers\n      Champions\n      26201.6\n    \n    \n      1\n      Recent Customers\n      Loyal Customers\n      35668.4\n    \n    \n      2\n      Promising\n      Champions\n      5086.2\n    \n    \n      3\n      Promising\n      Loyal Customers\n      7967.4\n    \n    \n      4\n      Customers Needing Attention\n      Champions\n      1688.0\n    \n    \n      5\n      Customers Needing Attention\n      Loyal Customers\n      3746.0\n    \n    \n      6\n      Hibernating\n      Champions\n      3158.0\n    \n    \n      7\n      Hibernating\n      Loyal Customers\n      5216.0\n    \n    \n      8\n      Lost\n      Champions\n      5382.6\n    \n    \n      9\n      Lost\n      Loyal Customers\n      6617.4\n    \n    \n      10\n      Lost\n      Recent Customers\n      465.0\n    \n    \n      11\n      Lost\n      Promising\n      1702.8\n    \n    \n      12\n      Lost\n      Customers Needing Attention\n      2869.8\n    \n    \n      13\n      Lost\n      Hibernating\n      1987.8\n    \n  \n\n\n\n\n\n\nCode\nloss=pd.DataFrame(Loss,columns=[\"From\",\"To\",\"Profit\"])\nloss\n\n\n\n\n\n\n  \n    \n      \n      From\n      To\n      Profit\n    \n  \n  \n    \n      0\n      Loyal Customers\n      Champions\n      -5469.6\n    \n    \n      1\n      Promising\n      Recent Customers\n      -6388.2\n    \n    \n      2\n      Customers Needing Attention\n      Recent Customers\n      -6508.0\n    \n    \n      3\n      Customers Needing Attention\n      Promising\n      -4445.0\n    \n    \n      4\n      Hibernating\n      Recent Customers\n      -5038.0\n    \n    \n      5\n      Hibernating\n      Promising\n      -2975.0\n    \n    \n      6\n      Hibernating\n      Customers Needing Attention\n      -1030.0"
  },
  {
    "objectID": "data-description.html",
    "href": "data-description.html",
    "title": "Data Description",
    "section": "",
    "text": "Data contains historical sales (2015 to 2018) of products in supermart. These products are categorized in 7 category:\n\n\nBakery\n\n\nBeverages\n\n\nEggs, Meat and Fish\n\n\nFood Grains\n\n\nFruits and Veggies\n\n\nOil and Masala\n\n\nSnacks\n\n\n\nData Dictionary\n\nOrder ID: Unique Id assign to each order  Customer Name: Name of the customer who purchased Customer Id: Unique Id assign to each customer Age: Age of the customer Gender: Gender type (ex. Male and Female) Category: Category of the product (ex. Bakery, Beverages, etc.) Sub Category: Sub Cateogry of the product (ex. Biscuits, Cakes, etc.) Region: Central, East, North, South, West State: State where products are purchased City: City where products are purchased Order Date: Purchase date Time: Purchase time Payment Method: Payment used by customer for purchase (ex. Cash, Ewallet, Credit card) Sales: Total sales amount  Quantity: Quantity purchased Discount: Discount percentage Profit: Profit amount Rating: Customer rating (1 to 10)\n\n\n\nSample Data\n\n\nCode\ndf=pd.read_csv('Supermart_Dataset.csv')\ndf.head().T\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n    \n  \n  \n    \n      Order ID\n      OD1\n      OD2\n      OD3\n      OD4\n      OD5\n    \n    \n      Customer Name\n      Harish\n      Sudha\n      Hussain\n      Jackson\n      Ridhesh\n    \n    \n      Customer Id\n      13\n      38\n      15\n      16\n      29\n    \n    \n      Age\n      53\n      31\n      18\n      69\n      12\n    \n    \n      Gender\n      Male\n      Female\n      Male\n      Male\n      Male\n    \n    \n      Category\n      Oil & Masala\n      Beverages\n      Food Grains\n      Fruits & Veggies\n      Food Grains\n    \n    \n      Sub Category\n      Masalas\n      Health Drinks\n      Atta & Flour\n      Fresh Vegetables\n      Organic Staples\n    \n    \n      Region\n      North\n      South\n      West\n      South\n      South\n    \n    \n      State\n      Tamil Nadu\n      Tamil Nadu\n      Tamil Nadu\n      Tamil Nadu\n      Tamil Nadu\n    \n    \n      City\n      Vellore\n      Krishnagiri\n      Perambalur\n      Dharmapuri\n      Ooty\n    \n    \n      Order Date\n      2017-11-08\n      2017-11-08\n      2017-06-12\n      2016-10-11\n      2016-10-11\n    \n    \n      Time\n      13:03:25\n      12:09:46\n      14:14:10\n      09:22:01\n      17:01:25\n    \n    \n      Payment Method\n      Cash\n      Cash\n      Credit card\n      Cash\n      Ewallet\n    \n    \n      Sales\n      1254\n      749\n      2360\n      896\n      2355\n    \n    \n      Quantity\n      7\n      14\n      22\n      13\n      8\n    \n    \n      Discount\n      0.12\n      0.18\n      0.21\n      0.25\n      0.26\n    \n    \n      Profit\n      401.28\n      149.8\n      165.2\n      89.6\n      918.45\n    \n    \n      Rating\n      8.0\n      1.0\n      1.0\n      8.0\n      9.0"
  }
]